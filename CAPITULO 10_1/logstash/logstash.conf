input {
  # Recibir logs desde microservicios vía TCP
  tcp {
    port => 5000
    codec => json
  }
  
  # Recibir logs vía UDP (opcional)
  udp {
    port => 5000
    codec => json
  }
}

filter {
  # Parsear timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Agregar campos calculados
  mutate {
    add_field => {
      "[@metadata][index_name]" => "quarkus-logs-%{+YYYY.MM.dd}"
    }
  }

  # Extraer información del servicio si viene en el mensaje
  if [logger_name] =~ /^pe\.banco\./ {
    grok {
      match => { "logger_name" => "pe\.banco\.%{WORD:service_name}\..*" }
    }
  }

  # Clasificar severidad de logs
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => ["alert"]
    }
  } else if [level] == "WARN" {
    mutate {
      add_tag => ["warning"]
    }
  }

  # Detectar patrones específicos (SAGA, Cache, Circuit Breaker)
  if [message] =~ /SAGA|saga/ {
    mutate {
      add_tag => ["saga"]
    }
  }

  if [message] =~ /Cache|cache|redis/i {
    mutate {
      add_tag => ["cache"]
    }
  }

  if [message] =~ /Circuit.*Breaker|circuit.*breaker/i {
    mutate {
      add_tag => ["circuit-breaker"]
    }
  }

  # Extraer compensación de SAGA
  if [message] =~ /compensaci[oó]n|compensat/ {
    mutate {
      add_tag => ["saga-compensation"]
    }
  }
}

output {
  # Enviar a Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_name]}"
  }

  # Debug output (comentar en producción)
  stdout {
    codec => rubydebug
  }
}
