# üìö TEOR√çA - Monitoreo con Grafana y Kibana en Entornos Quarkus

## Observabilidad en Arquitecturas de Microservicios

---

## üìã Tabla de Contenidos

1. [Introducci√≥n a la Observabilidad](#1-introducci√≥n-a-la-observabilidad)
2. [Los Tres Pilares de la Observabilidad](#2-los-tres-pilares-de-la-observabilidad)
3. [M√©tricas con Micrometer y Prometheus](#3-m√©tricas-con-micrometer-y-prometheus)
4. [Visualizaci√≥n con Grafana](#4-visualizaci√≥n-con-grafana)
5. [Logs Centralizados con Elastic Stack](#5-logs-centralizados-con-elastic-stack)
6. [Identificaci√≥n de Cuellos de Botella](#6-identificaci√≥n-de-cuellos-de-botella)
7. [Detecci√≥n de Patrones de Error](#7-detecci√≥n-de-patrones-de-error)
8. [PromQL: El Lenguaje de Prometheus](#8-promql-el-lenguaje-de-prometheus)
9. [Kibana Query Language (KQL)](#9-kibana-query-language-kql)
10. [Mejores Pr√°cticas de Observabilidad](#10-mejores-pr√°cticas-de-observabilidad)
11. [Antipatrones Comunes](#11-antipatrones-comunes)
12. [Casos de Uso Reales](#12-casos-de-uso-reales)

---

## 1. Introducci√≥n a la Observabilidad

### 1.1 ¬øQu√© es Observabilidad?

**Definici√≥n formal**: La observabilidad es una propiedad de un sistema que determina qu√© tan bien puedes entender su estado interno bas√°ndote √∫nicamente en sus salidas externas.

**Origen del t√©rmino**: Proviene de la teor√≠a de control en ingenier√≠a, donde un sistema es "observable" si puedes determinar su estado interno completo mediante sus salidas medibles.

### 1.2 Observabilidad vs Monitoreo

Hay una diferencia crucial entre estos conceptos:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MONITOREO                            ‚îÇ
‚îÇ  "¬øEst√° funcionando el sistema?"                        ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚Ä¢ Conoces las preguntas de antemano                   ‚îÇ
‚îÇ  ‚Ä¢ Dashboards predefinidos                             ‚îÇ
‚îÇ  ‚Ä¢ Alertas basadas en umbrales conocidos               ‚îÇ
‚îÇ  ‚Ä¢ Enfoque: Detectar problemas conocidos               ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Ejemplo: "¬øEl CPU est√° por encima del 80%?"          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  OBSERVABILIDAD                         ‚îÇ
‚îÇ  "¬øPor qu√© no est√° funcionando?"                       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚Ä¢ Puedes hacer preguntas arbitrarias                  ‚îÇ
‚îÇ  ‚Ä¢ Exploraci√≥n ad-hoc                                  ‚îÇ
‚îÇ  ‚Ä¢ Correlaci√≥n de eventos                              ‚îÇ
‚îÇ  ‚Ä¢ Enfoque: Entender problemas desconocidos            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Ejemplo: "¬øPor qu√© este request espec√≠fico tard√≥      ‚îÇ
‚îÇ            500ms m√°s que el anterior?"                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.3 Analog√≠a: El Sistema de Salud Humano

**Monitoreo** es como ir al m√©dico para un chequeo rutinario:
- Miden tu presi√≥n arterial (m√©trica conocida)
- Verifican tu peso (m√©trica conocida)
- Si algo est√° fuera de rango, suena una alarma

**Observabilidad** es como tener un an√°lisis completo de sangre cuando no te sientes bien pero no sabes por qu√©:
- El m√©dico puede explorar m√∫ltiples biomarcadores
- Correlacionar s√≠ntomas con resultados
- Descubrir problemas que no sab√≠as que exist√≠an

### 1.4 ¬øPor qu√© es Cr√≠tico en Microservicios?

En un monolito:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     MONOLITO        ‚îÇ
‚îÇ                     ‚îÇ
‚îÇ  - 1 proceso        ‚îÇ
‚îÇ  - 1 base de datos  ‚îÇ
‚îÇ  - 1 log file       ‚îÇ
‚îÇ  - F√°cil debuggear  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

En microservicios:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Svc1 ‚îÇ‚Üí‚îÇ Svc2 ‚îÇ‚Üí‚îÇ Svc3 ‚îÇ‚Üí‚îÇ Svc4 ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
   ‚ñº         ‚ñº         ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DB1 ‚îÇ  ‚îÇ DB2 ‚îÇ  ‚îÇ DB3 ‚îÇ  ‚îÇ DB4 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

- 4+ procesos
- 4+ bases de datos
- 4+ archivos de log
- ¬øCu√°l fall√≥? ¬øPor qu√©?
```

**Problemas sin observabilidad:**
1. **Efecto domin√≥**: Un servicio falla y no sabes cu√°l fue el primero
2. **Latencia distribuida**: Un request toca 10 servicios, ¬øcu√°l es lento?
3. **Logs dispersos**: Los logs est√°n en 20 m√°quinas diferentes
4. **Debugging imposible**: No puedes reproducir el problema en local

---

## 2. Los Tres Pilares de la Observabilidad

### 2.1 Pilar 1: M√©tricas (Metrics)

**¬øQu√© son?**
Representaciones num√©ricas agregadas del estado del sistema a lo largo del tiempo.

**Caracter√≠sticas:**
- **Estructura fija**: Siempre tienen la misma forma (timestamp + valor)
- **Bajo overhead**: Muy eficientes de almacenar y consultar
- **Agregables**: Puedes calcular promedios, percentiles, sumas
- **Time-series**: Evolucionan en el tiempo

**Tipos de m√©tricas:**

#### Counter (Contador)
Un valor que solo puede incrementar o resetearse a cero.

```
Ejemplo: N√∫mero total de requests HTTP procesados

Valor en el tiempo:
T0: 0
T1: 100
T2: 250
T3: 500

Uso t√≠pico:
- Total de requests
- Total de errores
- Total de bytes transferidos
```

#### Gauge (Medidor)
Un valor que puede subir o bajar libremente.

```
Ejemplo: Memoria RAM en uso

Valor en el tiempo:
T0: 512 MB
T1: 768 MB
T2: 620 MB
T3: 890 MB

Uso t√≠pico:
- Memoria en uso
- CPU en uso
- N√∫mero de conexiones activas
- Temperatura
```

#### Histogram (Histograma)
Distribuci√≥n de valores observados en buckets predefinidos.

```
Ejemplo: Latencia de requests HTTP

Buckets y observaciones:
[0-50ms]:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 200 requests
[50-100ms]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100 requests
[100-200ms]:‚ñà‚ñà‚ñà‚ñà 40 requests
[200-500ms]:‚ñà‚ñà 20 requests
[500ms+]:   ‚ñà 10 requests

Permite calcular:
- Percentil 50 (mediana)
- Percentil 95
- Percentil 99
```

#### Summary (Resumen)
Similar al histograma pero calcula percentiles directamente en el cliente.

```
Ejemplo: Latencia de llamadas a base de datos

Percentiles pre-calculados:
P50: 10ms
P90: 25ms
P95: 50ms
P99: 100ms
```

**Analog√≠a de m√©tricas**: Son como el veloc√≠metro, tac√≥metro y medidor de combustible de un auto. Te dan informaci√≥n num√©rica instant√°nea sobre el estado del sistema.

### 2.2 Pilar 2: Logs (Registros)

**¬øQu√© son?**
Eventos discretos con timestamp que describen lo que sucedi√≥ en el sistema.

**Caracter√≠sticas:**
- **Estructura variable**: Pueden tener diferentes campos
- **Alto nivel de detalle**: Incluyen contexto completo
- **No agregables**: Cada log es √∫nico
- **Alto overhead**: Ocupan mucho espacio

**Niveles de log:**

```
TRACE: Informaci√≥n extremadamente detallada (debugging profundo)
DEBUG: Informaci√≥n de debug (desarrollo)
INFO:  Eventos informativos normales
WARN:  Situaciones potencialmente problem√°ticas
ERROR: Errores que permiten continuar la ejecuci√≥n
FATAL: Errores cr√≠ticos que fuerzan el cierre del sistema
```

**Ejemplo de logs estructurados (JSON):**

```json
{
  "timestamp": "2025-10-23T14:32:15.123Z",
  "level": "ERROR",
  "service": "payment-service",
  "trace_id": "abc123",
  "span_id": "def456",
  "message": "Payment declined",
  "error": {
    "type": "InsufficientFundsException",
    "code": "PAYMENT_001",
    "details": "Customer balance: $50, required: $100"
  },
  "context": {
    "customer_id": "CUST-001",
    "order_id": "ORD-12345",
    "payment_method": "CREDIT_CARD"
  }
}
```

**Analog√≠a de logs**: Son como la caja negra de un avi√≥n. Registran cada evento importante que sucede, con todo el contexto necesario para reconstruir qu√© pas√≥.

### 2.3 Pilar 3: Trazas (Traces)

**¬øQu√© son?**
Representaci√≥n del recorrido completo de una request a trav√©s de m√∫ltiples servicios.

**Estructura de una traza:**

```
Trace ID: abc-123-def-456

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Span 1: HTTP GET /orders/123                            ‚îÇ
‚îÇ Service: order-service                                  ‚îÇ
‚îÇ Duration: 450ms                                         ‚îÇ
‚îÇ ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚îÇ                                                     ‚îÇ
‚îÇ   ‚îÇ Span 2: HTTP GET /inventory/check                   ‚îÇ
‚îÇ   ‚îÇ Service: inventory-service                          ‚îÇ
‚îÇ   ‚îÇ Duration: 80ms                                      ‚îÇ
‚îÇ   ‚îÇ Parent: Span 1                                      ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚îÇ                                                     ‚îÇ
‚îÇ   ‚îÇ Span 3: HTTP POST /payments/process                 ‚îÇ
‚îÇ   ‚îÇ Service: payment-service                            ‚îÇ
‚îÇ   ‚îÇ Duration: 320ms                                     ‚îÇ
‚îÇ   ‚îÇ Parent: Span 1                                      ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚îÇ                                                     ‚îÇ
‚îÇ   ‚îÇ Span 4: SQL SELECT FROM accounts                    ‚îÇ
‚îÇ   ‚îÇ Service: payment-service                            ‚îÇ
‚îÇ   ‚îÇ Duration: 250ms  ‚Üê CUELLO DE BOTELLA               ‚îÇ
‚îÇ   ‚îÇ Parent: Span 3                                      ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Analog√≠a de trazas**: Son como el GPS de un delivery. Puedes ver el camino exacto que tom√≥ el paquete, cu√°nto tard√≥ en cada punto, y d√≥nde se atasc√≥ en el tr√°fico.

### 2.4 Comparaci√≥n de los Tres Pilares

| Aspecto | M√©tricas | Logs | Trazas |
|---------|----------|------|--------|
| **Pregunta** | ¬øQu√© tan r√°pido/cu√°nto? | ¬øQu√© pas√≥ exactamente? | ¬øC√≥mo fluy√≥ la request? |
| **Cardinalidad** | Baja | Alta | Media |
| **Costo de almacenamiento** | Bajo | Alto | Medio |
| **Granularidad temporal** | Segundos/Minutos | Milisegundos | Milisegundos |
| **Agregaci√≥n** | S√≠ | No | No |
| **Uso principal** | Alertas, tendencias | Debugging, auditor√≠a | Performance, debugging distribuido |
| **Ejemplo** | "CPU al 80%" | "Error: Division by zero at line 42" | "Request tom√≥ 500ms: DB=300ms, API=200ms" |

---

## 3. M√©tricas con Micrometer y Prometheus

### 3.1 ¬øQu√© es Micrometer?

**Micrometer** es una fachada de instrumentaci√≥n para aplicaciones JVM, similar a SLF4J pero para m√©tricas en lugar de logs.

**Analog√≠a**: Micrometer es como un adaptador universal de enchufes. Tu c√≥digo habla el "lenguaje de Micrometer", pero las m√©tricas pueden exportarse a Prometheus, Graphite, InfluxDB, etc.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Tu C√≥digo Java    ‚îÇ
‚îÇ                     ‚îÇ
‚îÇ  counter.increment()‚îÇ
‚îÇ  timer.record()     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    MICROMETER       ‚îÇ ‚Üê Abstracci√≥n
‚îÇ   (Facade Layer)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº             ‚ñº          ‚ñº        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇPromethe‚îÇ  ‚îÇGraphite‚îÇ  ‚îÇInfluxDB‚îÇ  ‚îÇDatadog ‚îÇ
‚îÇ  us    ‚îÇ  ‚îÇ        ‚îÇ  ‚îÇ        ‚îÇ  ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 M√©tricas en Quarkus con Micrometer

#### Configuraci√≥n b√°sica en application.properties

```properties
# Habilitar Micrometer
quarkus.micrometer.enabled=true

# Habilitar exportador de Prometheus
quarkus.micrometer.export.prometheus.enabled=true

# Endpoint de m√©tricas
quarkus.micrometer.export.prometheus.path=/q/metrics

# M√©tricas de JVM
quarkus.micrometer.binder.jvm=true

# M√©tricas de sistema
quarkus.micrometer.binder.system=true

# M√©tricas HTTP
quarkus.micrometer.binder.http-server.enabled=true
```

#### Creaci√≥n de m√©tricas custom

```java
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.Timer;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;

@ApplicationScoped
public class InventoryService {

    @Inject
    MeterRegistry registry;

    private Counter cacheHitCounter;
    private Counter cacheMissCounter;
    private Timer queryTimer;

    @PostConstruct
    void init() {
        // Counter para cache hits
        cacheHitCounter = Counter.builder("cache.hits")
            .description("Number of cache hits")
            .tag("cache", "redis")
            .tag("type", "product")
            .register(registry);

        // Counter para cache misses
        cacheMissCounter = Counter.builder("cache.misses")
            .description("Number of cache misses")
            .tag("cache", "redis")
            .tag("type", "product")
            .register(registry);

        // Timer para medir duraci√≥n de queries
        queryTimer = Timer.builder("database.query.duration")
            .description("Database query execution time")
            .tag("operation", "findById")
            .register(registry);
    }

    public Product findById(String id) {
        // Intentar obtener de cache
        Product product = redis.get(id);
        
        if (product != null) {
            cacheHitCounter.increment();
            return product;
        }
        
        // Cache miss - consultar BD
        cacheMissCounter.increment();
        
        // Medir tiempo de query con Timer
        return queryTimer.record(() -> {
            Product result = database.findById(id);
            redis.set(id, result);
            return result;
        });
    }
}
```

### 3.3 ¬øQu√© es Prometheus?

**Prometheus** es un sistema de monitoreo y base de datos time-series dise√±ado para recolectar m√©tricas de manera pull-based.

#### Arquitectura de Prometheus

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               PROMETHEUS SERVER                  ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  Retrieval   ‚îÇ      ‚îÇ   Storage    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  (Scraping)  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (TSDB)      ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ         ‚îÇ                      ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                      ‚ñº                 ‚îÇ
‚îÇ         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ   Query      ‚îÇ         ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ   Engine     ‚îÇ         ‚îÇ
‚îÇ         ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ         ‚îÇ                     ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                     ‚îÇ
          ‚îÇ                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TARGETS           ‚îÇ   ‚îÇ  CONSUMERS    ‚îÇ
‚îÇ                    ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ - Microservicio 1  ‚îÇ   ‚îÇ - Grafana     ‚îÇ
‚îÇ - Microservicio 2  ‚îÇ   ‚îÇ - Alertmanager‚îÇ
‚îÇ - Microservicio 3  ‚îÇ   ‚îÇ - API Clients ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Pull vs Push Model

**Push Model (tradicional)**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Service  ‚îÇ‚îÄ‚îÄpush‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Monitor  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Problemas:
- El servicio debe saber d√≥nde est√° el monitor
- Si el monitor est√° ca√≠do, se pierden m√©tricas
- El servicio consume CPU enviando m√©tricas
```

**Pull Model (Prometheus)**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Service  ‚îÇ‚óÄ‚îÄ‚îÄpull‚îÄ‚îÄ‚îÄ‚îÇPrometheus‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Ventajas:
- El servicio solo expone endpoint HTTP
- Prometheus controla la frecuencia de scraping
- Si Prometheus est√° ca√≠do, el servicio no se ve afectado
- F√°cil de escalar horizontalmente
```

#### Configuraci√≥n de Prometheus (prometheus.yml)

```yaml
global:
  scrape_interval: 15s      # Cada cu√°nto scrapeamos
  evaluation_interval: 15s  # Cada cu√°nto evaluamos reglas

# Targets a scrapear
scrape_configs:
  - job_name: 'order-service'
    static_configs:
      - targets: ['localhost:8080']
        labels:
          service: 'order'
          env: 'dev'

  - job_name: 'inventory-service'
    static_configs:
      - targets: ['localhost:8081']
        labels:
          service: 'inventory'
          env: 'dev'

  - job_name: 'payment-service'
    static_configs:
      - targets: ['localhost:8082']
        labels:
          service: 'payment'
          env: 'dev'
```

### 3.4 Formato de M√©tricas de Prometheus

Las m√©tricas se exponen en formato texto plano:

```
# HELP http_server_requests_seconds Duration of HTTP server requests
# TYPE http_server_requests_seconds histogram
http_server_requests_seconds_bucket{method="GET",uri="/api/products",status="200",le="0.05"} 120
http_server_requests_seconds_bucket{method="GET",uri="/api/products",status="200",le="0.1"} 180
http_server_requests_seconds_bucket{method="GET",uri="/api/products",status="200",le="0.5"} 195
http_server_requests_seconds_bucket{method="GET",uri="/api/products",status="200",le="1.0"} 200
http_server_requests_seconds_bucket{method="GET",uri="/api/products",status="200",le="+Inf"} 200
http_server_requests_seconds_count{method="GET",uri="/api/products",status="200"} 200
http_server_requests_seconds_sum{method="GET",uri="/api/products",status="200"} 18.5

# HELP jvm_memory_used_bytes The amount of used memory
# TYPE jvm_memory_used_bytes gauge
jvm_memory_used_bytes{area="heap",id="G1 Eden Space"} 2.4576E7
jvm_memory_used_bytes{area="heap",id="G1 Old Gen"} 1.2345E7
jvm_memory_used_bytes{area="nonheap",id="Metaspace"} 4.567E7
```

**Elementos clave:**
- **HELP**: Descripci√≥n de la m√©trica
- **TYPE**: Tipo (counter, gauge, histogram, summary)
- **Labels**: Dimensiones adicionales (method, uri, status, etc.)
- **Value**: Valor num√©rico de la m√©trica

---

## 4. Visualizaci√≥n con Grafana

### 4.1 ¬øQu√© es Grafana?

**Grafana** es una plataforma de visualizaci√≥n y an√°lisis de datos que permite crear dashboards interactivos conect√°ndose a m√∫ltiples fuentes de datos.

**Analog√≠a**: Grafana es como Excel + PowerBI pero especializado en time-series y observabilidad. Puedes crear gr√°ficas, tablas, heatmaps, y todo actualizado en tiempo real.

### 4.2 Arquitectura de Grafana

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   GRAFANA                          ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Dashboards  ‚îÇ  ‚îÇ    Panels    ‚îÇ  ‚îÇ Queries ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ                 ‚îÇ                ‚îÇ      ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                           ‚îÇ                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                     ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇPrometheus‚îÇ  ‚îÇ InfluxDB ‚îÇ  ‚îÇElasticsea‚îÇ  ‚îÇPostgreSQL‚îÇ
    ‚îÇ          ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ   rch    ‚îÇ  ‚îÇ          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.3 Componentes de un Dashboard

#### Panel
La unidad b√°sica de visualizaci√≥n. Puede ser:
- **Graph**: L√≠nea de tiempo cl√°sica
- **Stat**: Valor √∫nico grande
- **Gauge**: Medidor circular o lineal
- **Bar gauge**: Barras horizontales
- **Table**: Tabla de datos
- **Heatmap**: Mapa de calor
- **Logs**: Panel de logs

#### Variables
Permiten crear dashboards din√°micos:

```
Dashboard Variables:
- $service = [order, inventory, payment]
- $environment = [dev, staging, prod]
- $interval = [1m, 5m, 15m]

Query con variables:
rate(http_server_requests_seconds_count{
  job="$service-service",
  env="$environment"
}[$interval])
```

#### Annotations
Marcadores de eventos importantes:

```
Ejemplos:
- "Deploy v1.2.3 - 14:30"
- "Incidente resuelto - 15:45"
- "Aumento de tr√°fico - 16:00"
```

### 4.4 Dashboards Efectivos: Principios de Dise√±o

#### M√©todo RED (Rate, Errors, Duration)

Para servicios, siempre monitorea:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         DASHBOARD: Order Service        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ  Panel 1: RATE (Requests per second)   ‚îÇ
‚îÇ  ‚ñ≤                                      ‚îÇ
‚îÇ  ‚îÇ     ‚ï±‚ï≤                               ‚îÇ
‚îÇ  ‚îÇ    ‚ï±  ‚ï≤    ‚ï±‚ï≤                        ‚îÇ
‚îÇ  ‚îÇ   ‚ï±    ‚ï≤  ‚ï±  ‚ï≤                       ‚îÇ
‚îÇ  ‚îÇ‚îÄ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Panel 2: ERRORS (Error rate %)        ‚îÇ
‚îÇ  ‚ñ≤                                      ‚îÇ
‚îÇ  ‚îÇ                  ‚ï±‚ï≤                  ‚îÇ
‚îÇ  ‚îÇ                 ‚ï±  ‚ï≤                 ‚îÇ
‚îÇ  ‚îÇ                ‚ï±    ‚ï≤                ‚îÇ
‚îÇ  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Panel 3: DURATION (Latency P95)       ‚îÇ
‚îÇ  ‚ñ≤                                      ‚îÇ
‚îÇ  ‚îÇ         ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤                       ‚îÇ
‚îÇ  ‚îÇ        ‚ï±      ‚ï≤                      ‚îÇ
‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±        ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                ‚îÇ
‚îÇ  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂     ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### M√©todo USE (Utilization, Saturation, Errors)

Para recursos (CPU, memoria, disco):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      DASHBOARD: System Resources        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ  Panel 1: CPU Utilization (%)          ‚îÇ
‚îÇ  Panel 2: Memory Utilization (%)       ‚îÇ
‚îÇ  Panel 3: Disk I/O Saturation          ‚îÇ
‚îÇ  Panel 4: Network Errors               ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.5 Alertas en Grafana

Grafana puede enviar alertas cuando las m√©tricas cruzan umbrales:

```yaml
Alert: High Error Rate

Condition:
  WHEN avg() OF query(A, 5m, now)
  IS ABOVE 0.05

Evaluate every: 1m
For: 5m

Notifications:
  - Slack: #alerts
  - Email: oncall@company.com
  - PagerDuty: escalation-policy-1

Message:
  "üö® Error rate is {{ $value }}% on {{ $labels.service }}"
```

---

## 5. Logs Centralizados con Elastic Stack

### 5.1 ¬øQu√© es Elastic Stack (ELK)?

**Elastic Stack** (anteriormente ELK Stack) es un conjunto de herramientas para la gesti√≥n centralizada de logs.

**Componentes:**
- **E**lasticsearch: Motor de b√∫squeda y almacenamiento
- **L**ogstash: Procesador y transformador de logs
- **K**ibana: Interfaz de visualizaci√≥n
- **B**eats: Agentes ligeros de recolecci√≥n

### 5.2 Arquitectura de Elastic Stack

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MICROSERVICIOS                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇOrder Svc‚îÇ  ‚îÇInventory‚îÇ  ‚îÇPayment  ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  Svc    ‚îÇ  ‚îÇ  Svc    ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ       ‚îÇ            ‚îÇ            ‚îÇ                   ‚îÇ
‚îÇ       ‚îÇ  Escriben logs a archivo                    ‚îÇ
‚îÇ       ‚îÇ            ‚îÇ            ‚îÇ                   ‚îÇ
‚îÇ       ‚ñº            ‚ñº            ‚ñº                   ‚îÇ
‚îÇ  order.log   inventory.log  payment.log            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ            ‚îÇ            ‚îÇ
        ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
        ‚îÇ     ‚îÇ  FILEBEAT   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ     ‚îÇ  (Shipper)  ‚îÇ
        ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   LOGSTASH   ‚îÇ ‚Üê Parsing, filtering, enrichment
              ‚îÇ  (Pipeline)  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇELASTICSEARCH ‚îÇ ‚Üê Indexing & Storage
              ‚îÇ   (Store)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ    KIBANA    ‚îÇ ‚Üê Visualization & Search
              ‚îÇ    (UI)      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.3 Elasticsearch: El Motor de B√∫squeda

#### ¬øQu√© es Elasticsearch?

Un motor de b√∫squeda y an√°lisis distribuido basado en **Apache Lucene**.

**Conceptos clave:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ELASTICSEARCH CLUSTER           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ         INDEX: quarkus-logs    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Shard 0 ‚îÇ  ‚îÇ  Shard 1 ‚îÇ   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Primary)‚îÇ  ‚îÇ (Primary)‚îÇ   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Shard 0 ‚îÇ  ‚îÇ  Shard 1 ‚îÇ   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Replica)‚îÇ  ‚îÇ (Replica)‚îÇ   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Index = Base de datos
Shard = Partici√≥n de datos
Replica = Copia de respaldo
Document = Registro individual (log)
```

#### Ejemplo de documento indexado

```json
{
  "_index": "quarkus-logs-2025.10.23",
  "_id": "abc123",
  "_score": 1.0,
  "_source": {
    "@timestamp": "2025-10-23T14:30:15.123Z",
    "level": "ERROR",
    "service_name": "payment-service",
    "logger_name": "pe.banco.payment.service.PaymentService",
    "message": "Payment processing failed",
    "exception": {
      "class": "pe.banco.payment.exception.InsufficientFundsException",
      "message": "Insufficient funds",
      "stacktrace": "..."
    },
    "trace_id": "abc-def-ghi",
    "span_id": "123-456",
    "customer_id": "CUST-001",
    "order_id": "ORD-789",
    "amount": 100.00
  }
}
```

### 5.4 Logstash: El Pipeline de Procesamiento

Logstash procesa logs en tres etapas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INPUT   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ FILTER  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ OUTPUT  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Configuraci√≥n de Logstash

```ruby
# logstash.conf

input {
  # Recibir logs de Filebeat
  beats {
    port => 5044
  }
}

filter {
  # Parsear logs JSON
  if [message] =~ /^{.*}$/ {
    json {
      source => "message"
    }
  }

  # Extraer informaci√≥n del logger_name
  if [logger_name] {
    grok {
      match => {
        "logger_name" => "pe\.banco\.(?<service_component>\w+)\..*"
      }
    }
  }

  # Enriquecer con geolocalizaci√≥n (si hay IP)
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Agregar tags basados en nivel de log
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => ["alert"]
    }
  }

  # Calcular duraci√≥n si existe
  if [duration_ms] {
    ruby {
      code => "event.set('duration_seconds', event.get('duration_ms') / 1000.0)"
    }
  }
}

output {
  # Enviar a Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "quarkus-logs-%{+YYYY.MM.dd}"
  }

  # Debug: imprimir en stdout (opcional)
  # stdout { codec => rubydebug }
}
```

### 5.5 Kibana: Visualizaci√≥n y B√∫squeda

#### Discover: Exploraci√≥n de Logs

Kibana Discover permite:
1. **Buscar logs** con query language
2. **Filtrar** por campos
3. **Ver contexto** alrededor de un log
4. **Crear visualizaciones** desde b√∫squedas

#### Kibana Query Language (KQL)

```
# B√∫squedas b√°sicas
level: ERROR
service_name: "order-service"

# Operadores l√≥gicos
level: ERROR AND service_name: "order-service"
level: ERROR OR level: FATAL

# Rangos num√©ricos
duration_ms > 1000
status_code >= 500 AND status_code < 600

# Wildcards
message: *timeout*
customer_id: CUST-*

# Negaci√≥n
NOT level: DEBUG
NOT service_name: "inventory-service"

# Campos anidados
exception.class: "InsufficientFundsException"
geoip.country_name: "United States"

# B√∫squeda de texto completo
message: "payment failed"

# Existe campo
_exists_: exception
NOT _exists_: trace_id
```

#### Visualizaciones en Kibana

```
Tipos de visualizaciones:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Vertical Bar Chart              ‚îÇ
‚îÇ    - Logs por nivel en el tiempo   ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ 2. Line Chart                      ‚îÇ
‚îÇ    - Tendencia de errores          ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ 3. Pie Chart                       ‚îÇ
‚îÇ    - Distribuci√≥n por servicio     ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ 4. Data Table                      ‚îÇ
‚îÇ    - Top 10 errores m√°s comunes    ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ 5. Tag Cloud                       ‚îÇ
‚îÇ    - Palabras m√°s frecuentes       ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ 6. Metric                          ‚îÇ
‚îÇ    - Total de errores (n√∫mero)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 6. Identificaci√≥n de Cuellos de Botella

### 6.1 ¬øQu√© es un Cuello de Botella?

**Definici√≥n**: Un punto en el sistema que limita el rendimiento general, como el cuello estrecho de una botella limita el flujo de l√≠quido.

**Analog√≠a del supermercado**:
```
Entrada ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Pasillos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Cajas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Salida
(r√°pido)       (r√°pido)       (LENTO)       (bloqueado)
                                  ‚ñ≤
                            CUELLO DE BOTELLA
```

Si tienes 10 cajas registradoras pero solo 2 est√°n abiertas, no importa qu√© tan r√°pido la gente encuentre sus productos - todos esperar√°n en las cajas.

### 6.2 Metodolog√≠a para Identificar Cuellos de Botella

#### Paso 1: Medir la Latencia End-to-End

**En Grafana:**
```promql
# Latencia P95 de cada endpoint
histogram_quantile(0.95,
  sum by (uri) (
    rate(http_server_requests_seconds_bucket[5m])
  )
)
```

**Resultado esperado:**
```
/api/orders/create     ‚Üí 850ms ‚Üê LENTO
/api/orders/list       ‚Üí 50ms
/api/products/search   ‚Üí 80ms
/api/payments/process  ‚Üí 120ms
```

#### Paso 2: Descomponer la Latencia

**En Kibana, buscar logs del endpoint lento:**
```
uri: "/api/orders/create" AND level: DEBUG
```

**Analizar los tiempos:**
```
2025-10-23T14:30:00.000Z DEBUG Iniciando creaci√≥n de orden
2025-10-23T14:30:00.050Z DEBUG Validando inventario...       [50ms]
2025-10-23T14:30:00.750Z DEBUG Reservando inventario...      [700ms] ‚Üê CUELLO DE BOTELLA
2025-10-23T14:30:00.800Z DEBUG Procesando pago...            [50ms]
2025-10-23T14:30:00.850Z DEBUG Orden creada exitosamente     [50ms]
```

#### Paso 3: Analizar la Operaci√≥n Lenta

**Posibles causas de "Reservando inventario" tarda 700ms:**

1. **Query SQL lento** (falta √≠ndice)
2. **N+1 queries** (consulta en loop)
3. **Lock de base de datos** (transacci√≥n bloqueada)
4. **Network latency** (BD en otra regi√≥n)
5. **Cache miss** (deber√≠a estar en Redis)

**Verificar con m√©tricas:**
```promql
# Ver queries a la BD
rate(jdbc_connections_active[1m])

# Ver latencia de queries SQL
histogram_quantile(0.95,
  rate(jdbc_query_seconds_bucket{operation="reserve_inventory"}[5m])
)
```

### 6.3 T√©cnicas de Optimizaci√≥n

#### T√©cnica 1: Indexaci√≥n de Base de Datos

**Problema detectado:**
```sql
-- Query lento (full table scan)
SELECT * FROM products WHERE product_code = 'LAPTOP-001';

-- Explain muestra:
-- Seq Scan on products (cost=0.00..100.00 rows=5000 width=200)
```

**Soluci√≥n:**
```sql
-- Crear √≠ndice
CREATE INDEX idx_products_code ON products(product_code);

-- Ahora:
-- Index Scan using idx_products_code (cost=0.00..8.27 rows=1 width=200)
```

**Resultado:**
- Antes: 700ms
- Despu√©s: 50ms
- **Mejora: 14x m√°s r√°pido**

#### T√©cnica 2: Implementar Cache

**Problema:**
```
Cada request consulta BD:
Request 1 ‚Üí BD ‚Üí 50ms
Request 2 ‚Üí BD ‚Üí 50ms
Request 3 ‚Üí BD ‚Üí 50ms
...
Request 100 ‚Üí BD ‚Üí 50ms

Total: 5000ms para 100 requests
```

**Soluci√≥n con Redis:**
```
Request 1 ‚Üí BD ‚Üí Redis ‚Üí 50ms (cache miss)
Request 2 ‚Üí Redis ‚Üí 5ms (cache hit)
Request 3 ‚Üí Redis ‚Üí 5ms (cache hit)
...
Request 100 ‚Üí Redis ‚Üí 5ms (cache hit)

Total: 545ms para 100 requests
```

**Resultado: 9x m√°s r√°pido**

#### T√©cnica 3: Procesamiento As√≠ncrono

**Problema:**
```
POST /orders/create

[Cliente espera 5 segundos]

1. Validar inventario     (1s)
2. Procesar pago          (2s)
3. Enviar email           (1s) ‚Üê No cr√≠tico
4. Notificar warehouse    (1s) ‚Üê No cr√≠tico

Response: 200 OK
```

**Soluci√≥n:**
```
POST /orders/create

[Cliente espera 3 segundos]

1. Validar inventario     (1s)
2. Procesar pago          (2s)

Response: 202 Accepted

[En background - async]
3. Enviar email           (1s)
4. Notificar warehouse    (1s)
```

**Resultado: 40% m√°s r√°pido (perceived)**

### 6.4 Ley de Amdahl

**Teorema**: El speed-up m√°ximo est√° limitado por la porci√≥n secuencial del c√≥digo.

```
Speedup = 1 / ((1 - P) + P/N)

P = Porci√≥n paralelizable
N = N√∫mero de procesadores
```

**Ejemplo pr√°ctico:**

Si el 90% de tu c√≥digo es paralelizable:
```
1 CPU:   1x speedup
2 CPUs:  1.8x speedup
4 CPUs:  3.1x speedup
8 CPUs:  4.7x speedup
16 CPUs: 6.4x speedup
‚àû CPUs:  10x speedup (l√≠mite)
```

**Lecci√≥n**: Optimiza primero la parte secuencial (el 10% en este caso) antes de agregar m√°s CPUs.

---

## 7. Detecci√≥n de Patrones de Error

### 7.1 Clasificaci√≥n de Errores

#### Errores Transitorios (Transient Errors)

**Caracter√≠sticas:**
- Ocurren temporalmente
- Se resuelven solos o con retry
- No requieren cambios en el c√≥digo

**Ejemplos:**
```
- Network timeout
- Connection pool exhausted
- Deadlock en BD (se resuelve al reintentar)
- Rate limit exceeded (esperar y reintentar)
```

**Patr√≥n en Grafana:**
```
Error Rate
   ‚ñ≤
   ‚îÇ    ‚ï±‚ï≤
   ‚îÇ   ‚ï±  ‚ï≤
   ‚îÇ  ‚ï±    ‚ï≤
   ‚îÇ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Tiempo
   ‚îÇ
   ‚îî‚îÄ Pico breve, luego vuelve a 0%
```

**Soluci√≥n:**
```java
@Retry(maxRetries = 3, delay = 1000)
@Fallback(fallbackMethod = "paymentFallback")
public PaymentResponse processPayment(PaymentRequest request) {
    // C√≥digo que puede fallar temporalmente
}
```

#### Errores Permanentes (Permanent Errors)

**Caracter√≠sticas:**
- No se resuelven solos
- Requieren intervenci√≥n humana
- Indican bugs o problemas de configuraci√≥n

**Ejemplos:**
```
- NullPointerException
- ArrayIndexOutOfBoundsException
- SQL syntax error
- Missing configuration property
```

**Patr√≥n en Grafana:**
```
Error Rate
   ‚ñ≤
   ‚îÇ         ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   ‚îÇ        ‚ï±
   ‚îÇ       ‚ï±
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Tiempo
   ‚îÇ
   ‚îî‚îÄ Sube y se mantiene alto
```

**Soluci√≥n:**
- Fix del bug
- Deploy de hotfix
- Rollback a versi√≥n anterior

#### Errores en Cascada (Cascading Failures)

**Caracter√≠sticas:**
- Un servicio falla y provoca falla en otros
- Efecto domin√≥
- Puede colapsar todo el sistema

**Ejemplo:**
```
T0: Payment Service falla (error rate 100%)
    ‚Üì
T1: Order Service empieza a fallar (llama a Payment)
    ‚Üì
T2: Frontend muestra errores a usuarios
    ‚Üì
T3: Usuarios recargan p√°gina (m√°s carga)
    ‚Üì
T4: Sistema colapsa completamente
```

**Patr√≥n en Grafana:**
```
Error Rate por Servicio

Payment:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
            T0 ‚Üí
Order:           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
                 T1 ‚Üí
Frontend:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 90%
                      T2 ‚Üí
```

**Soluci√≥n: Circuit Breaker**
```java
@CircuitBreaker(
    requestVolumeThreshold = 10,
    failureRatio = 0.5,
    delay = 5000
)
public PaymentResponse processPayment() {
    // Si falla 50% de 10 requests
    // ‚Üí Circuit OPEN (no llamar por 5 segundos)
}
```

### 7.2 T√©cnicas de Detecci√≥n en Kibana

#### Pattern 1: Spike de Errores

**Query en Kibana:**
```
level: ERROR
```

**Visualizaci√≥n:**
- Date Histogram (1 minuto)
- Ver picos inusuales

**An√°lisis:**
```
Normal:    ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
Spike:     ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
                ‚Üë
           ¬øQu√© pas√≥ aqu√≠?
```

**Correlacionar con:**
- Deploys
- Cambios de configuraci√≥n
- Aumento de tr√°fico
- Ca√≠das de servicios externos

#### Pattern 2: Error Recurrente

**Query en Kibana:**
```
level: ERROR AND exception.class: "InsufficientFundsException"
```

**Agrupar por:**
- Customer ID
- Order ID
- Payment method

**Descubrimiento:**
```
Customer CUST-001: 50 errores en 1 hora
Customer CUST-002: 2 errores en 1 hora
Customer CUST-003: 1 error en 1 hora

‚Üí CUST-001 est√° haciendo algo mal (bot? retry loop?)
```

#### Pattern 3: Degradaci√≥n Gradual

**Query en Kibana:**
```
message: *slow* OR message: *timeout*
```

**Visualizaci√≥n:**
- Trend line de duraci√≥n promedio

**An√°lisis:**
```
Duraci√≥n Promedio
   ‚ñ≤
   ‚îÇ               ‚ï±
   ‚îÇ              ‚ï±
   ‚îÇ          ‚ï±‚ï±‚ï±
   ‚îÇ    ‚ï±‚ï±‚ï±‚ï±
   ‚îÇ‚ï±‚ï±‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Tiempo
   ‚îÇ
   ‚îî‚îÄ Performance empeorando gradualmente
```

**Posibles causas:**
- Memory leak
- Tabla de BD creciendo sin √≠ndices
- Cache inefectivo
- Conexiones de BD no liberadas

### 7.3 Correlaci√≥n de Eventos

#### T√©cnica: Buscar Causa Ra√≠z

**Paso 1: Identificar el primer error**
```
Kibana Query:
level: ERROR
Sort by: @timestamp (ascending)
```

**Paso 2: Ver contexto temporal**
```
- ¬øQu√© pas√≥ 5 minutos antes?
- ¬øHay logs de WARNING?
- ¬øHay cambios en m√©tricas?
```

**Paso 3: Seguir el trace_id**
```
trace_id: "abc-123-def"

Resultado:
2025-10-23T14:30:00.000Z order-service    INFO  Request received
2025-10-23T14:30:00.050Z inventory-service INFO  Checking inventory
2025-10-23T14:30:00.100Z inventory-service ERROR Database timeout ‚Üê CAUSA RA√çZ
2025-10-23T14:30:05.000Z order-service    ERROR Inventory check failed
```

### 7.4 Alertas Inteligentes

#### Alerta B√°sica (Umbral Est√°tico)

```yaml
Alert: High Error Rate

Condition:
  error_rate > 5%

Problema:
  - Puede haber falsos positivos en bajo tr√°fico
  - No detecta cambios relativos
```

#### Alerta Avanzada (Anomal√≠a)

```yaml
Alert: Anomalous Error Rate

Condition:
  error_rate > (avg_last_7_days + 3 * stddev)

Ventaja:
  - Se adapta al patr√≥n normal
  - Detecta cambios relativos
```

#### Alerta Predictiva (Machine Learning)

```
Usa ML para predecir:
- "La memoria se llenar√° en 2 horas"
- "El disco alcanzar√° 90% en 30 minutos"

Permite: Acci√≥n proactiva antes del problema
```

---

## 8. PromQL: El Lenguaje de Prometheus

### 8.1 Sintaxis B√°sica

#### Seleccionar una M√©trica

```promql
# Todas las series de tiempo de esta m√©trica
http_server_requests_seconds_count

# Filtrar por labels
http_server_requests_seconds_count{job="order-service"}

# M√∫ltiples labels
http_server_requests_seconds_count{
  job="order-service",
  method="GET",
  uri="/api/orders"
}

# Regex en labels
http_server_requests_seconds_count{
  status=~"5.."  # 500, 501, 502, etc.
}
```

### 8.2 Funciones de Agregaci√≥n

#### rate() - Tasa por segundo

```promql
# Calcula requests por segundo en los √∫ltimos 5 minutos
rate(http_server_requests_seconds_count[5m])

# ¬øC√≥mo funciona?
# Toma el valor al final - valor al inicio
# Divide por el tiempo transcurrido
# 
# Ejemplo:
# t=0:  counter=100
# t=5m: counter=400
# rate = (400-100) / 300s = 1 request/sec
```

#### sum() - Suma

```promql
# Total de requests en todos los servicios
sum(rate(http_server_requests_seconds_count[5m]))

# Total por servicio
sum by (job) (rate(http_server_requests_seconds_count[5m]))
```

#### avg() - Promedio

```promql
# Latencia promedio
avg(http_server_requests_seconds_sum / http_server_requests_seconds_count)
```

#### max() / min() - M√°ximo / M√≠nimo

```promql
# Memoria m√°xima usada por cualquier servicio
max(jvm_memory_used_bytes{area="heap"})

# Memoria m√≠nima usada
min(jvm_memory_used_bytes{area="heap"})
```

### 8.3 Percentiles con histogram_quantile()

```promql
# Latencia P50 (mediana)
histogram_quantile(0.50,
  rate(http_server_requests_seconds_bucket[5m])
)

# Latencia P95
histogram_quantile(0.95,
  rate(http_server_requests_seconds_bucket[5m])
)

# Latencia P99
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket[5m])
)

# ¬øPor qu√© usar P95 en lugar de promedio?
# Promedio: 50ms (parece bien)
# P95: 500ms (¬°5% de usuarios tienen mala experiencia!)
```

### 8.4 Operaciones Matem√°ticas

```promql
# Error rate (porcentaje)
rate(http_server_requests_seconds_count{status=~"5.."}[5m])
/
rate(http_server_requests_seconds_count[5m])
* 100

# Cache hit rate
cache_hits_total
/
(cache_hits_total + cache_misses_total)
* 100

# Memoria disponible (GB)
(jvm_memory_max_bytes - jvm_memory_used_bytes) / 1024^3
```

### 8.5 Queries √ötiles para Copiar

```promql
# ===== M√âTRICAS DE SERVICIO =====

# Requests por segundo por servicio
sum by (job) (rate(http_server_requests_seconds_count[1m]))

# Latencia P95 por endpoint
histogram_quantile(0.95,
  sum by (uri, le) (rate(http_server_requests_seconds_bucket[5m]))
)

# Error rate por servicio
sum by (job) (rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
/
sum by (job) (rate(http_server_requests_seconds_count[5m]))

# ===== M√âTRICAS DE JVM =====

# Heap memory usado (%)
(jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"}) * 100

# GC pause time (ms)
rate(jvm_gc_pause_seconds_sum[5m]) * 1000

# Threads activos
jvm_threads_live_threads

# ===== M√âTRICAS DE BD =====

# Conexiones activas a PostgreSQL
jdbc_connections_active{pool="HikariPool-1"}

# Tiempo de espera por conexi√≥n (ms)
rate(jdbc_connections_wait_seconds_sum[5m]) * 1000

# ===== M√âTRICAS DE CACHE =====

# Redis cache hit rate
redis_cache_hits_total / (redis_cache_hits_total + redis_cache_misses_total)

# ===== M√âTRICAS DE SISTEMA =====

# CPU usage (%)
system_cpu_usage * 100

# Disk usage (%)
(disk_total_bytes - disk_free_bytes) / disk_total_bytes * 100
```

---

## 9. Kibana Query Language (KQL)

### 9.1 Sintaxis B√°sica

```
# B√∫squeda simple
error

# Campo espec√≠fico
level: ERROR

# Frase exacta
message: "payment failed"

# Wildcard
customer_id: CUST-*

# Rango num√©rico
duration_ms > 1000
status_code >= 500 AND status_code < 600

# Existe campo
_exists_: exception

# No existe campo
NOT _exists_: trace_id
```

### 9.2 Operadores L√≥gicos

```
# AND
level: ERROR AND service_name: "order-service"

# OR
level: ERROR OR level: FATAL

# NOT
NOT level: DEBUG

# Agrupaci√≥n con par√©ntesis
(level: ERROR OR level: FATAL) AND service_name: "payment-service"
```

### 9.3 Queries √ötiles

```
# ===== ERRORES =====

# Todos los errores
level: ERROR

# Errores de un servicio espec√≠fico
level: ERROR AND service_name: "payment-service"

# Errores con exception
level: ERROR AND _exists_: exception

# Top errores por tipo
exception.class: *

# ===== PERFORMANCE =====

# Requests lentos (>1 segundo)
duration_ms > 1000

# Timeouts
message: *timeout* OR message: *timed out*

# ===== SAGA =====

# Compensaciones SAGA
tags: saga-compensation

# SAGA fallidas
tags: saga AND level: ERROR

# ===== CACHE =====

# Cache hits
message: "Cache HIT"

# Cache misses
message: "Cache MISS"

# ===== B√öSQUEDA POR CONTEXTO =====

# Logs de una orden espec√≠fica
order_id: "ORD-12345"

# Logs de un cliente espec√≠fico
customer_id: "CUST-001"

# Logs de una traza distribuida
trace_id: "abc-123-def"
```

---

## 10. Mejores Pr√°cticas de Observabilidad

### 10.1 Structured Logging

‚ùå **MAL:**
```java
logger.info("Order created with id " + orderId + " for customer " + customerId);
```

‚úÖ **BIEN:**
```java
logger.info("Order created",
    kv("order_id", orderId),
    kv("customer_id", customerId),
    kv("amount", order.getTotalAmount())
);
```

**Resultado en JSON:**
```json
{
  "message": "Order created",
  "order_id": "ORD-123",
  "customer_id": "CUST-001",
  "amount": 99.99
}
```

**Ventajas:**
- F√°cil de buscar en Kibana: `order_id: "ORD-123"`
- F√°cil de agregar: Count by customer_id
- No depende de parsing de texto

### 10.2 Semantic Logging

Usa **niveles de log** apropiados:

```java
// TRACE: Informaci√≥n muy detallada (solo desarrollo)
logger.trace("Entering method calculateTotal()");

// DEBUG: Informaci√≥n √∫til para debugging
logger.debug("Cache miss for product {}", productCode);

// INFO: Eventos importantes del negocio
logger.info("Order created successfully", kv("order_id", orderId));

// WARN: Situaciones inusuales pero manejables
logger.warn("Inventory low for product {}", productCode);

// ERROR: Errores que permiten continuar
logger.error("Failed to send email notification", exception);

// FATAL: Errores cr√≠ticos (sistema no puede continuar)
logger.fatal("Database connection pool exhausted");
```

### 10.3 Correlation IDs

**Siempre propagar trace_id y span_id:**

```
Request 1: Order Service
  trace_id: abc-123
  span_id: span-1
  
  ‚Üì Llama a Inventory Service
  
  trace_id: abc-123  (mismo!)
  span_id: span-2
  parent_span_id: span-1
  
  ‚Üì Llama a Payment Service
  
  trace_id: abc-123  (mismo!)
  span_id: span-3
  parent_span_id: span-1
```

**En Kibana:**
```
trace_id: "abc-123"

Resultado: Todos los logs de esta request a trav√©s de los 3 servicios
```

### 10.4 M√©tricas con Contexto

‚ùå **MAL:**
```java
counter.increment();
```

‚úÖ **BIEN:**
```java
counter.tag("operation", "reserve_inventory")
       .tag("product_type", "electronics")
       .tag("success", "true")
       .increment();
```

**Ventajas en Grafana:**
```promql
# Puedes filtrar por contexto
sum by (operation) (inventory_operations_total)

# Comparar success vs failure
sum(inventory_operations_total{success="true"})
/
sum(inventory_operations_total)
```

### 10.5 SLIs, SLOs y SLAs

#### SLI (Service Level Indicator)

**Definici√≥n**: M√©trica que mide el nivel de servicio.

**Ejemplos:**
```
- Latencia P95 < 500ms
- Error rate < 0.1%
- Availability > 99.9%
```

#### SLO (Service Level Objective)

**Definici√≥n**: Target interno para un SLI.

**Ejemplo:**
```
SLO: "El 95% de las requests deben completarse en menos de 500ms"

Query PromQL:
histogram_quantile(0.95,
  rate(http_server_requests_seconds_bucket[5m])
) < 0.5
```

#### SLA (Service Level Agreement)

**Definici√≥n**: Contrato con consecuencias si no se cumple.

**Ejemplo:**
```
SLA: "99.9% uptime mensual"

Si incumplimos: Cr√©dito de 10% a clientes
```

#### Error Budget

```
SLO: 99.9% availability = 0.1% error budget

C√°lculo:
- Mes: 30 d√≠as = 43,200 minutos
- Error budget: 43.2 minutos de downtime permitidos

Tracking:
- Semana 1: 5 minutos de downtime (quedan 38.2 min)
- Semana 2: 10 minutos de downtime (quedan 28.2 min)
- Semana 3: 30 minutos de downtime (quedan -1.8 min) ‚Üê EXCEEDED!

Acci√≥n: Freeze deploys, focus en stability
```

---

## 11. Antipatrones Comunes

### 11.1 Alert Fatigue

‚ùå **Problema:**
```
Alertas cada 5 minutos:
- CPU > 80%
- Memory > 80%
- Disk > 80%
- Error rate > 1%
- Latency > 100ms

Resultado: Ingeniero ignora todas las alertas
```

‚úÖ **Soluci√≥n:**
```
Alertas solo para:
- SLO violado durante 5 minutos
- Error budget exhausted
- Incidente cr√≠tico

Resultado: Cada alerta es importante
```

### 11.2 Vanity Metrics

‚ùå **M√©tricas in√∫tiles:**
```
- Total de usuarios registrados (no dice si est√°n activos)
- Total de requests (no dice si son exitosos)
- Latencia promedio (oculta outliers)
```

‚úÖ **M√©tricas accionables:**
```
- Usuarios activos diarios (DAU)
- Success rate (%)
- Latencia P95/P99 (experiencia real)
```

### 11.3 Logging Everything

‚ùå **Problema:**
```java
logger.debug("Entering method");
logger.debug("Parameter x = " + x);
logger.debug("Calling database");
logger.debug("Database returned");
logger.debug("Processing result");
logger.debug("Exiting method");
```

**Costo:**
- Disco lleno en horas
- Elasticsearch colapsa
- Imposible encontrar logs importantes

‚úÖ **Soluci√≥n:**
```java
// Solo log eventos importantes
logger.info("Order processing started", kv("order_id", orderId));

try {
    result = processOrder(order);
    logger.info("Order processed successfully", kv("order_id", orderId));
} catch (Exception e) {
    logger.error("Order processing failed", kv("order_id", orderId), e);
}
```

### 11.4 Dashboards Incomprensibles

‚ùå **Dashboard malo:**
```
- 50 paneles en un dashboard
- Gr√°ficas sin t√≠tulo
- Ejes sin unidades
- Sin anotaciones de eventos
- Colores aleatorios
```

‚úÖ **Dashboard bueno:**
```
- 5-10 paneles por dashboard
- T√≠tulos descriptivos
- Unidades claras (ms, GB, %)
- Anotaciones de deploys
- Colores con significado (rojo=mal, verde=bien)
```

---

## 12. Casos de Uso Reales

### 12.1 Caso: Netflix

**Problema:**
Sistema distribuido con miles de microservicios. Dif√≠cil saber d√≥nde est√°n los problemas.

**Soluci√≥n:**
- **Atlas**: Sistema de m√©tricas custom basado en time-series
- **Spectator**: Librer√≠a para instrumentaci√≥n
- **Vizceral**: Visualizaci√≥n de tr√°fico en tiempo real

**Resultado:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Vizceral Dashboard                ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ   [Frontend] ‚îÄ‚îÄ‚îÄ‚ñ∂ [API Gateway]    ‚îÇ
‚îÇ        ‚îÇ                ‚îÇ           ‚îÇ
‚îÇ        ‚îÇ                ‚ñº           ‚îÇ
‚îÇ        ‚îÇ         [Recommendations] ‚îÇ
‚îÇ        ‚îÇ                ‚îÇ           ‚îÇ
‚îÇ        ‚ñº                ‚ñº           ‚îÇ
‚îÇ   [Content] ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ [Personalization]‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ   Color del edge = Health           ‚îÇ
‚îÇ   - Verde: OK                       ‚îÇ
‚îÇ   - Amarillo: Warning               ‚îÇ
‚îÇ   - Rojo: Critical                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Lecci√≥n:** Visualizaci√≥n en tiempo real ayuda a detectar problemas instant√°neamente.

### 12.2 Caso: Uber

**Problema:**
Miles de eventos por segundo. Debugging de un ride espec√≠fico es imposible.

**Soluci√≥n:**
- **Jaeger**: Distributed tracing
- Cada request tiene trace_id √∫nico
- Logs estructurados con trace_id

**Resultado:**
```
Uber Engineer busca en Jaeger:
trace_id: "ride-123"

Ve:
1. Request recibido en API
2. B√∫squeda de drivers cercanos (100ms)
3. C√°lculo de ETA (50ms)
4. C√°lculo de precio (200ms) ‚Üê LENTO
5. Match driver-rider (30ms)

Identifica: Servicio de pricing es el cuello de botella
```

**Lecci√≥n:** Distributed tracing es esencial para debugging en sistemas complejos.

### 12.3 Caso: Amazon Prime Day

**Problema:**
Tr√°fico 10x normal durante Prime Day. Sistema colapsa cada a√±o.

**Soluci√≥n:**
- **Load testing** previo con tr√°fico realista
- **Auto-scaling** agresivo
- **Circuit breakers** en todos los servicios
- **Chaos engineering** (simular fallos antes del evento)

**M√©tricas clave monitoreadas:**
```
- Requests per second
- Latency P99
- Error rate
- Database connections
- Cache hit rate
- Auto-scaling events
```

**Resultado:**
```
Prima Day 2023:
- 375 millones de items vendidos
- Pico de 1 mill√≥n de requests/segundo
- 99.99% uptime
- 0 incidents cr√≠ticos
```

**Lecci√≥n:** Observabilidad + preparaci√≥n = resiliencia.

---

## üìö Conclusi√≥n

La observabilidad no es un lujo - es una **necesidad** en arquitecturas de microservicios.

### Puntos Clave

1. **Los 3 pilares** (m√©tricas, logs, trazas) son complementarios
2. **Micrometer + Prometheus** para m√©tricas eficientes
3. **Grafana** para visualizaci√≥n intuitiva
4. **ELK Stack** para logs centralizados y searchables
5. **Cuellos de botella** se identifican con m√©tricas + logs
6. **Patrones de error** requieren correlaci√≥n de eventos

### Siguiente Nivel

Para llevar tu observabilidad al siguiente nivel:

1. **Implementa distributed tracing** con OpenTelemetry + Jaeger
2. **Define SLOs** para tus servicios cr√≠ticos
3. **Automatiza alertas** basadas en error budget
4. **Practica chaos engineering** para validar resiliencia
5. **Construye runbooks** para cada alerta

---

**"You can't improve what you don't measure."** - Peter Drucker

La observabilidad te da los ojos para ver, los o√≠dos para escuchar, y el cerebro para entender qu√© est√° pasando en tu sistema distribuido.

---

## üìñ Referencias y Recursos

### Libros
- **"Distributed Systems Observability"** - Cindy Sridharan (O'Reilly)
- **"The Art of Monitoring"** - James Turnbull
- **"Site Reliability Engineering"** - Google (SRE Book)

### Documentaci√≥n Oficial
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Elastic Stack Documentation](https://www.elastic.co/guide/)
- [Quarkus Micrometer Guide](https://quarkus.io/guides/micrometer)

### Cursos y Tutoriales
- [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)
- [Grafana Fundamentals](https://grafana.com/tutorials/)
- [Elasticsearch Fundamentals](https://www.elastic.co/training/)

### Papers Acad√©micos
- **"Dapper: A Large-Scale Distributed Systems Tracing Infrastructure"** - Google (2010)
- **"Monarch: Google's Planet-Scale In-Memory Time Series Database"** - Google (2020)

---

**Fin del documento te√≥rico. Practica con el ejercicio hands-on para consolidar estos conceptos.**